{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTGu_vhOK_S7",
        "outputId": "03caec8c-ed72-4d90-968f-bbe33a9c0f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.185.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        " !pip install gradio google-generativeai pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rpmlgBUebjDL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers>=4.52.4 torchaudio peft soundfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcD7pDk7bbn6",
        "outputId": "fcc6e47b-8dec-42fa-a557-62bf367cdf12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=493ebbe6b234ad283f639996a2032bdacfbf2990afdf328b5dead64836f30b45\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqYGNP0ZK_jU",
        "outputId": "82d10017-8960-407b-904c-8a67e3dee13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gtts) (2.32.4)\n",
            "Collecting click<8.2,>=7.1 (from gtts)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2025.10.5)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gtts\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "Successfully installed click-8.1.8 gtts-2.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JvsL6en6v2GW"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2 gradio google-generativeai gtts langdetect transformers>=4.52.4 torchaudio peft soundfile huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w53teKB3t6rz",
        "outputId": "f6976e31-cfcc-49c3-d318-8b128b7816af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "SUCCESS: gradio installed successfully\n",
            "SUCCESS: google-generativeai installed successfully\n",
            "SUCCESS: gtts installed successfully\n",
            "SUCCESS: langdetect installed successfully\n",
            "SUCCESS: transformers>=4.52.4 installed successfully\n",
            "SUCCESS: torchaudio installed successfully\n",
            "SUCCESS: peft installed successfully\n",
            "SUCCESS: soundfile installed successfully\n",
            "SUCCESS: huggingface-hub installed successfully\n",
            "SUCCESS: PyPDF2 installed successfully\n",
            "\n",
            "======================================================================\n",
            "ECHO VERSE - AI-POWERED AUDIOBOOK CREATION TOOL\n",
            "======================================================================\n",
            "Features:\n",
            "   * Automatic language detection (25+ languages)\n",
            "   * Gemini AI text enhancement\n",
            "   * IBM Granite speech-to-text\n",
            "   * High-quality audiobook generation\n",
            "   * User category customization\n",
            "   * Black UI with green accents\n",
            "======================================================================\n",
            "Required: Gemini API key from https://makersuite.google.com/app/apikey\n",
            "GPU recommended for Granite model performance\n",
            "======================================================================\n",
            "Starting Echo Verse - AI-Powered Audiobook Creation Tool...\n",
            "The app will be accessible via the generated Gradio link\n",
            "Device: cuda\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ffe8d0507e6a96ef2c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ffe8d0507e6a96ef2c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from gtts import gTTS\n",
        "import io\n",
        "import base64\n",
        "from langdetect import detect\n",
        "import langdetect\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# IBM Granite model imports\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "from huggingface_hub import hf_hub_download\n",
        "import soundfile as sf\n",
        "import tempfile\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "class MultilingualTTSWithGranite:\n",
        "    def __init__(self):\n",
        "        self.gemini_model = None\n",
        "        self.granite_model = None\n",
        "        self.granite_processor = None\n",
        "        self.granite_tokenizer = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        self.supported_languages = {\n",
        "            'en': 'English',\n",
        "            'hi': 'Hindi',\n",
        "            'ur': 'Urdu',\n",
        "            'te': 'Telugu',\n",
        "            'ta': 'Tamil',\n",
        "            'bn': 'Bengali',\n",
        "            'gu': 'Gujarati',\n",
        "            'kn': 'Kannada',\n",
        "            'ml': 'Malayalam',\n",
        "            'mr': 'Marathi',\n",
        "            'pa': 'Punjabi',\n",
        "            'or': 'Odia',\n",
        "            'as': 'Assamese',\n",
        "            'es': 'Spanish',\n",
        "            'fr': 'French',\n",
        "            'de': 'German',\n",
        "            'it': 'Italian',\n",
        "            'pt': 'Portuguese',\n",
        "            'ru': 'Russian',\n",
        "            'ja': 'Japanese',\n",
        "            'ko': 'Korean',\n",
        "            'zh': 'Chinese',\n",
        "            'ar': 'Arabic',\n",
        "            'tr': 'Turkish',\n",
        "            'th': 'Thai',\n",
        "            'vi': 'Vietnamese'\n",
        "        }\n",
        "\n",
        "        # User profile storage\n",
        "        self.user_profile = {\n",
        "            'category': None,\n",
        "            'preferences': {}\n",
        "        }\n",
        "\n",
        "    def configure_gemini(self, api_key):\n",
        "        \"\"\"Configure Gemini API with provided key\"\"\"\n",
        "        try:\n",
        "            genai.configure(api_key=api_key)\n",
        "            self.gemini_model = genai.GenerativeModel('gemini-pro')\n",
        "            return \"SUCCESS: Gemini API configured successfully!\"\n",
        "        except Exception as e:\n",
        "            return f\"ERROR: Error configuring Gemini API: {str(e)}\"\n",
        "\n",
        "    def initialize_granite_model(self):\n",
        "        \"\"\"Initialize IBM Granite speech model\"\"\"\n",
        "        try:\n",
        "            model_name = \"ibm-granite/granite-speech-3.3-2b\"\n",
        "            self.granite_processor = AutoProcessor.from_pretrained(model_name)\n",
        "            self.granite_tokenizer = self.granite_processor.tokenizer\n",
        "            self.granite_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "                model_name,\n",
        "                device_map=self.device,\n",
        "                torch_dtype=torch.bfloat16\n",
        "            )\n",
        "            return \"SUCCESS: IBM Granite model loaded successfully!\"\n",
        "        except Exception as e:\n",
        "            return f\"ERROR: Error loading Granite model: {str(e)}\"\n",
        "\n",
        "    def speech_to_text_granite(self, audio_file):\n",
        "        \"\"\"Convert speech to text using IBM Granite model\"\"\"\n",
        "        if not audio_file:\n",
        "            return \"\", \"Please upload an audio file\"\n",
        "\n",
        "        if not self.granite_model:\n",
        "            init_result = self.initialize_granite_model()\n",
        "            if \"ERROR\" in init_result:\n",
        "                return \"\", init_result\n",
        "\n",
        "        try:\n",
        "            # Load and process audio\n",
        "            wav, sr = torchaudio.load(audio_file, normalize=True)\n",
        "\n",
        "            # Resample to 16kHz if needed\n",
        "            if sr != 16000:\n",
        "                resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "                wav = resampler(wav)\n",
        "\n",
        "            # Ensure mono audio\n",
        "            if wav.shape[0] > 1:\n",
        "                wav = torch.mean(wav, dim=0, keepdim=True)\n",
        "\n",
        "            # Create prompts\n",
        "            system_prompt = \"Knowledge Cutoff Date: April 2024.\\nToday's Date: April 9, 2025.\\nYou are Granite, developed by IBM. You are a helpful AI assistant\"\n",
        "            user_prompt = \"<|audio|>can you transcribe the speech into a written format?\"\n",
        "\n",
        "            chat = [\n",
        "                dict(role=\"system\", content=system_prompt),\n",
        "                dict(role=\"user\", content=user_prompt),\n",
        "            ]\n",
        "\n",
        "            prompt = self.granite_tokenizer.apply_chat_template(\n",
        "                chat, tokenize=False, add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            # Process with model\n",
        "            model_inputs = self.granite_processor(\n",
        "                prompt, wav, device=self.device, return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            model_outputs = self.granite_model.generate(\n",
        "                **model_inputs, max_new_tokens=200, do_sample=False, num_beams=1\n",
        "            )\n",
        "\n",
        "            # Extract transcription\n",
        "            num_input_tokens = model_inputs[\"input_ids\"].shape[-1]\n",
        "            new_tokens = torch.unsqueeze(model_outputs[0, num_input_tokens:], dim=0)\n",
        "            output_text = self.granite_tokenizer.batch_decode(\n",
        "                new_tokens, add_special_tokens=False, skip_special_tokens=True\n",
        "            )\n",
        "\n",
        "            transcribed_text = output_text[0].strip()\n",
        "            return transcribed_text, \"SUCCESS: Speech transcribed successfully with IBM Granite!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return \"\", f\"ERROR: Speech-to-text error: {str(e)}\"\n",
        "\n",
        "    def translate_text(self, text, source_lang, target_lang, api_key):\n",
        "        \"\"\"Translate text using Gemini\"\"\"\n",
        "        if not self.gemini_model:\n",
        "            config_result = self.configure_gemini(api_key)\n",
        "            if \"ERROR\" in config_result:\n",
        "                return text, config_result\n",
        "\n",
        "        try:\n",
        "            source_name = self.supported_languages.get(source_lang, source_lang)\n",
        "            target_name = self.supported_languages.get(target_lang, target_lang)\n",
        "\n",
        "            prompt = f\"Translate this text from {source_name} to {target_name}. Only return the translation, nothing else: {text}\"\n",
        "\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            translated_text = response.text.strip()\n",
        "\n",
        "            return translated_text, f\"SUCCESS: Translated from {source_name} to {target_name}\"\n",
        "        except Exception as e:\n",
        "            return text, f\"ERROR: Translation failed: {str(e)}\"\n",
        "\n",
        "    def detect_language(self, text):\n",
        "        \"\"\"Detect language of input text\"\"\"\n",
        "        try:\n",
        "            detected_lang = detect(text)\n",
        "            if detected_lang in self.supported_languages:\n",
        "                return detected_lang, self.supported_languages[detected_lang]\n",
        "            else:\n",
        "                return 'en', 'English (Fallback)'\n",
        "        except LangDetectException:\n",
        "            return 'en', 'English (Default)'\n",
        "\n",
        "    def enhance_text_with_gemini(self, text, user_category):\n",
        "        \"\"\"Use Gemini to enhance text based on user category\"\"\"\n",
        "        if not self.gemini_model:\n",
        "            return text, \"Gemini not configured\"\n",
        "\n",
        "        try:\n",
        "            category_prompts = {\n",
        "                'student': f\"Enhance this text to make it more educational and clear for a student: {text}\",\n",
        "                'working_professional': f\"Make this text more professional and concise for a working professional: {text}\",\n",
        "                'visually_impaired': f\"Make this text more descriptive and accessible for someone who is visually impaired, adding context where helpful: {text}\",\n",
        "                'other': f\"Improve the clarity and flow of this text: {text}\"\n",
        "            }\n",
        "\n",
        "            prompt = category_prompts.get(user_category, category_prompts['other'])\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            enhanced_text = response.text\n",
        "\n",
        "            return enhanced_text, \"SUCCESS: Text enhanced by Gemini\"\n",
        "        except Exception as e:\n",
        "            return text, f\"ERROR: Gemini enhancement failed: {str(e)}\"\n",
        "\n",
        "    def text_to_speech(self, text, lang_code, slow_speech=False):\n",
        "        \"\"\"Convert text to speech\"\"\"\n",
        "        try:\n",
        "            tts = gTTS(text=text, lang=lang_code, slow=slow_speech)\n",
        "            audio_buffer = io.BytesIO()\n",
        "            tts.write_to_fp(audio_buffer)\n",
        "            audio_buffer.seek(0)\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:\n",
        "                tmp_file.write(audio_buffer.getvalue())\n",
        "                tmp_file_path = tmp_file.name\n",
        "\n",
        "            return tmp_file_path\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"TTS Error: {str(e)}\")\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file):\n",
        "        \"\"\"Extract text from uploaded PDF file\"\"\"\n",
        "        try:\n",
        "            if pdf_file is None:\n",
        "                return \"\"\n",
        "\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error extracting PDF text: {str(e)}\"\n",
        "\n",
        "    def process_complete_workflow(self, input_text, pdf_file, audio_file,\n",
        "                                target_language, gemini_key, use_granite_stt,\n",
        "                                user_category, enhance_with_gemini, slow_speech):\n",
        "        \"\"\"Complete workflow: PDF extraction, STT, translation, and TTS\"\"\"\n",
        "        try:\n",
        "            # Setup Gemini if key provided\n",
        "            gemini_status = \"\"\n",
        "            if gemini_key and gemini_key.strip():\n",
        "                gemini_status = self.configure_gemini(gemini_key.strip())\n",
        "\n",
        "            # Extract text from PDF if provided\n",
        "            pdf_text = \"\"\n",
        "            if pdf_file:\n",
        "                pdf_text = self.extract_text_from_pdf(pdf_file)\n",
        "\n",
        "            # Transcribe audio if provided and Granite STT is enabled\n",
        "            audio_text = \"\"\n",
        "            if audio_file and use_granite_stt:\n",
        "                if self.granite_model is None:\n",
        "                    granite_status = self.initialize_granite_model()\n",
        "                audio_text, _ = self.speech_to_text_granite(audio_file)\n",
        "\n",
        "            # Combine all text sources\n",
        "            combined_text = []\n",
        "            if input_text and input_text.strip():\n",
        "                combined_text.append(f\"Input Text:\\n{input_text.strip()}\")\n",
        "            if pdf_text:\n",
        "                combined_text.append(f\"PDF Content:\\n{pdf_text[:2000]}{'...' if len(pdf_text) > 2000 else ''}\")\n",
        "            if audio_text:\n",
        "                combined_text.append(f\"Audio Transcription:\\n{audio_text}\")\n",
        "\n",
        "            if not combined_text:\n",
        "                return \"No text to process\", \"\", None, None, gemini_status\n",
        "\n",
        "            source_text = \"\\n\\n\".join(combined_text)\n",
        "\n",
        "            # Detect language\n",
        "            lang_code, lang_name = self.detect_language(source_text)\n",
        "            detection_info = f\"Detected Language: {lang_name} ({lang_code})\"\n",
        "\n",
        "            # Enhance text if requested\n",
        "            processed_text = source_text\n",
        "            enhancement_info = \"\"\n",
        "            if enhance_with_gemini:\n",
        "                processed_text, enhancement_status = self.enhance_text_with_gemini(source_text, user_category)\n",
        "                enhancement_info = f\"Gemini Enhancement: {enhancement_status}\"\n",
        "\n",
        "            # Translate text if needed\n",
        "            translated_text = processed_text\n",
        "            if target_language != \"English\":\n",
        "                target_lang_name = self.supported_languages.get(target_language.lower(), target_language)\n",
        "                translated_text, _ = self.translate_text(processed_text, lang_code, target_language.lower(), gemini_key)\n",
        "\n",
        "            # Generate TTS for original text\n",
        "            original_audio = self.text_to_speech(processed_text, lang_code, slow_speech)\n",
        "\n",
        "            # Generate TTS for translated text\n",
        "            translated_audio = None\n",
        "            if target_language != \"English\" and translated_text != processed_text:\n",
        "                target_code = target_language.lower()[:2]  # Get language code\n",
        "                if target_code in self.supported_languages:\n",
        "                    translated_audio = self.text_to_speech(translated_text, target_code, slow_speech)\n",
        "\n",
        "            status_message = f\"SUCCESS: Processing completed!\\n{detection_info}\\n{enhancement_info}\"\n",
        "\n",
        "            return (processed_text, translated_text, original_audio,\n",
        "                   translated_audio, status_message)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error in workflow: {str(e)}\", \"\", None, None, \"Error occurred\"\n",
        "\n",
        "# Initialize the TTS system\n",
        "tts_system = MultilingualTTSWithGranite()\n",
        "\n",
        "# Enhanced CSS with black background and green accents\n",
        "custom_css = \"\"\"\n",
        "/* Force dark theme with black background */\n",
        ".gradio-container {\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
        "    background: #000000 !important;\n",
        "    color: #ffffff !important;\n",
        "}\n",
        "\n",
        "body, .gradio-container, .app, .main, .block, .container {\n",
        "    background: #000000 !important;\n",
        "    color: #ffffff !important;\n",
        "}\n",
        "\n",
        "/* Input styling */\n",
        ".gr-textbox, .gr-dropdown, .gr-file, .gr-checkbox, .gr-radio, textarea, input, select {\n",
        "    background: #1a1a1a !important;\n",
        "    color: #ffffff !important;\n",
        "    border: 2px solid #00ff00 !important;\n",
        "    border-radius: 8px !important;\n",
        "}\n",
        "\n",
        "/* Button styling */\n",
        ".gr-button {\n",
        "    background: linear-gradient(135deg, #00ff00 0%, #00cc00 100%) !important;\n",
        "    color: #000000 !important;\n",
        "    border: none !important;\n",
        "    font-weight: bold !important;\n",
        "    border-radius: 8px !important;\n",
        "    padding: 10px 20px !important;\n",
        "    transition: all 0.3s ease !important;\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background: linear-gradient(135deg, #00cc00 0%, #009900 100%) !important;\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 4px 15px rgba(0, 255, 0, 0.4) !important;\n",
        "}\n",
        "\n",
        "/* Headers and labels */\n",
        "label, .gr-form label, .gr-block-title, h1, h2, h3, h4, h5, h6 {\n",
        "    color: #ffffff !important;\n",
        "    font-weight: bold !important;\n",
        "}\n",
        "\n",
        "/* Tab styling */\n",
        ".gr-tab-nav button {\n",
        "    background: #1a1a1a !important;\n",
        "    color: #ffffff !important;\n",
        "    border: 1px solid #00ff00 !important;\n",
        "}\n",
        "\n",
        ".gr-tab-nav button.selected {\n",
        "    background: linear-gradient(135deg, #00ff00 0%, #00cc00 100%) !important;\n",
        "    color: #000000 !important;\n",
        "}\n",
        "\n",
        "/* Output areas */\n",
        ".gr-textbox[data-testid=\"textbox\"] {\n",
        "    background: #1a1a1a !important;\n",
        "    color: #ffffff !important;\n",
        "    border: 1px solid #00ff00 !important;\n",
        "}\n",
        "\n",
        "/* Audio player */\n",
        "audio {\n",
        "    background: #1a1a1a !important;\n",
        "    border: 1px solid #00ff00 !important;\n",
        "    border-radius: 8px !important;\n",
        "}\n",
        "\n",
        "/* File upload */\n",
        ".gr-file-upload {\n",
        "    background: #1a1a1a !important;\n",
        "    border: 2px dashed #00ff00 !important;\n",
        "    color: #ffffff !important;\n",
        "    border-radius: 8px !important;\n",
        "}\n",
        "\n",
        "/* Special containers */\n",
        ".title-header {\n",
        "    text-align: center;\n",
        "    background: linear-gradient(135deg, #1a1a1a 0%, #2a2a2a 100%);\n",
        "    color: #00ff00;\n",
        "    padding: 25px;\n",
        "    border-radius: 15px;\n",
        "    margin-bottom: 20px;\n",
        "    border: 2px solid #00ff00;\n",
        "}\n",
        "\n",
        ".feature-section {\n",
        "    background: #1a1a1a;\n",
        "    color: #ffffff;\n",
        "    padding: 20px;\n",
        "    border-radius: 12px;\n",
        "    margin: 15px 0;\n",
        "    border-left: 5px solid #00ff00;\n",
        "}\n",
        "\n",
        "/* Accordion */\n",
        ".gr-accordion {\n",
        "    background: #1a1a1a !important;\n",
        "    border: 1px solid #00ff00 !important;\n",
        "    border-radius: 8px !important;\n",
        "}\n",
        "\n",
        "/* Progress bars */\n",
        ".gr-progress {\n",
        "    background: #00ff00 !important;\n",
        "}\n",
        "\n",
        "/* Links */\n",
        "a {\n",
        "    color: #00ff00 !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def create_interface():\n",
        "    with gr.Blocks(css=custom_css, title=\"AI-Powered Multilingual Speech System\") as interface:\n",
        "\n",
        "        # Header\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"title-header\">\n",
        "            <h1>Echo Verse - AI Powered Audiobook Creation Tool</h1>\n",
        "            <h3>Gemini AI + IBM Granite + Google TTS</h3>\n",
        "            <p>Professional audiobook creation with Text-to-Speech and Speech-to-Text in 25+ languages!</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # User Category Selection\n",
        "        gr.HTML('<h3 style=\"color: #00ff00;\">Welcome! Please tell us about yourself:</h3>')\n",
        "\n",
        "        user_category = gr.Radio(\n",
        "            choices=[\"student\", \"working_professional\", \"visually_impaired\", \"other\"],\n",
        "            label=\"I am a:\",\n",
        "            value=\"student\",\n",
        "            interactive=True\n",
        "        )\n",
        "\n",
        "        # API Configuration\n",
        "        with gr.Accordion(\"API Configuration\", open=True):\n",
        "            api_key_input = gr.Textbox(\n",
        "                label=\"Gemini API Key\",\n",
        "                placeholder=\"Enter your Google Gemini API key here...\",\n",
        "                type=\"password\",\n",
        "                info=\"Get your free API key from: https://makersuite.google.com/app/apikey\"\n",
        "            )\n",
        "\n",
        "            granite_init_btn = gr.Button(\"Initialize IBM Granite Model\", variant=\"secondary\")\n",
        "            granite_status = gr.Textbox(label=\"Granite Model Status\", interactive=False)\n",
        "\n",
        "        # Main Features Tabs\n",
        "        with gr.Tabs():\n",
        "\n",
        "            # Complete Workflow Tab\n",
        "            with gr.TabItem(\"Complete Workflow\"):\n",
        "                gr.HTML('<div class=\"feature-section\">')\n",
        "                gr.HTML(\"<h3>Multi-Source Processing</h3>\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        # Input sources\n",
        "                        input_text = gr.Textbox(\n",
        "                            label=\"Text Input\",\n",
        "                            placeholder=\"Type or paste text in any language\",\n",
        "                            lines=5\n",
        "                        )\n",
        "\n",
        "                        pdf_upload = gr.File(\n",
        "                            label=\"Upload PDF Document\",\n",
        "                            file_types=[\".pdf\"],\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "\n",
        "                        audio_upload = gr.File(\n",
        "                            label=\"Upload Audio File\",\n",
        "                            file_types=[\".wav\", \".mp3\", \".m4a\", \".ogg\"],\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "\n",
        "                        # Options\n",
        "                        target_language = gr.Dropdown(\n",
        "                            label=\"Target Language\",\n",
        "                            choices=[\"English\", \"Spanish\", \"French\", \"German\", \"Hindi\", \"Chinese\", \"Japanese\"],\n",
        "                            value=\"English\"\n",
        "                        )\n",
        "\n",
        "                        use_granite_stt = gr.Checkbox(\n",
        "                            label=\"Use IBM Granite for Speech-to-Text\",\n",
        "                            value=True\n",
        "                        )\n",
        "\n",
        "                        enhance_with_gemini = gr.Checkbox(\n",
        "                            label=\"Enhance text with Gemini AI\",\n",
        "                            value=True\n",
        "                        )\n",
        "\n",
        "                        slow_speech = gr.Checkbox(\n",
        "                            label=\"Generate slow speech\",\n",
        "                            value=False\n",
        "                        )\n",
        "\n",
        "                        process_btn = gr.Button(\"Process All Sources\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                # Output Section\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.HTML(\"<h3>Original Text & Audio</h3>\")\n",
        "                        original_output = gr.Textbox(\n",
        "                            label=\"Processed Original Text\",\n",
        "                            lines=8,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        original_audio = gr.Audio(label=\"Original Audio\", type=\"filepath\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        gr.HTML(\"<h3>Translated Text & Audio</h3>\")\n",
        "                        translated_output = gr.Textbox(\n",
        "                            label=\"Translated Text\",\n",
        "                            lines=8,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        translated_audio = gr.Audio(label=\"Translated Audio\", type=\"filepath\")\n",
        "\n",
        "                status_output = gr.Textbox(\n",
        "                    label=\"Processing Status\",\n",
        "                    lines=3,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                gr.HTML('</div>')\n",
        "\n",
        "            # Text-to-Speech Tab\n",
        "            with gr.TabItem(\"Text-to-Speech Only\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        tts_text_input = gr.Textbox(\n",
        "                            label=\"Enter text to convert to speech\",\n",
        "                            placeholder=\"Type text in any language\",\n",
        "                            lines=5\n",
        "                        )\n",
        "\n",
        "                        tts_enhance_checkbox = gr.Checkbox(\n",
        "                            label=\"Enhance text with Gemini AI\",\n",
        "                            value=True\n",
        "                        )\n",
        "\n",
        "                        tts_slow_speech_checkbox = gr.Checkbox(\n",
        "                            label=\"Generate slow speech\",\n",
        "                            value=False\n",
        "                        )\n",
        "\n",
        "                        tts_generate_btn = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "                        tts_audio_output = gr.Audio(label=\"Generated Speech\", type=\"filepath\")\n",
        "                        tts_status_output = gr.Textbox(label=\"Status\", lines=3, interactive=False)\n",
        "                        tts_enhanced_text_output = gr.Textbox(label=\"Enhanced Text\", lines=4, interactive=False)\n",
        "\n",
        "            # Speech-to-Text Tab\n",
        "            with gr.TabItem(\"Speech-to-Text Only\"):\n",
        "                gr.HTML('<h3>IBM Granite Speech Recognition</h3>')\n",
        "\n",
        "                stt_audio_input = gr.Audio(\n",
        "                    label=\"Upload Audio File\",\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "\n",
        "                stt_transcribe_btn = gr.Button(\"Transcribe with Granite\", variant=\"secondary\")\n",
        "\n",
        "                stt_transcribed_output = gr.Textbox(\n",
        "                    label=\"Transcribed Text\",\n",
        "                    lines=5,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                stt_status = gr.Textbox(\n",
        "                    label=\"Transcription Status\",\n",
        "                    lines=2,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        # Quick Test Samples\n",
        "        with gr.Accordion(\"Quick Test Samples\", open=False):\n",
        "            gr.HTML(\"<h4>Try these sample texts:</h4>\")\n",
        "\n",
        "            with gr.Row():\n",
        "                sample_hindi = gr.Button(\"Hindi Sample\")\n",
        "                sample_telugu = gr.Button(\"Telugu Sample\")\n",
        "                sample_urdu = gr.Button(\"Urdu Sample\")\n",
        "                sample_english = gr.Button(\"English Sample\")\n",
        "\n",
        "        # Language Support Information\n",
        "        with gr.Accordion(\"Supported Languages\", open=False):\n",
        "            lang_list = []\n",
        "            for code, name in tts_system.supported_languages.items():\n",
        "                lang_list.append(f\"• {name} ({code})\")\n",
        "\n",
        "            gr.HTML(f\"\"\"\n",
        "            <div style=\"background: #1a1a1a; padding: 15px; border-radius: 10px; border: 1px solid #00ff00;\">\n",
        "                <div style=\"columns: 3; column-gap: 20px; color: #ffffff;\">\n",
        "                    {chr(10).join(lang_list)}\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "        # Event Handlers\n",
        "\n",
        "        # Complete Workflow\n",
        "        process_btn.click(\n",
        "            fn=tts_system.process_complete_workflow,\n",
        "            inputs=[\n",
        "                input_text, pdf_upload, audio_upload, target_language,\n",
        "                api_key_input, use_granite_stt, user_category,\n",
        "                enhance_with_gemini, slow_speech\n",
        "            ],\n",
        "            outputs=[\n",
        "                original_output, translated_output,\n",
        "                original_audio, translated_audio, status_output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # TTS Only\n",
        "        def process_tts_only(text, api_key, category, enhance, slow):\n",
        "            if not text.strip():\n",
        "                return None, \"Please enter some text\", \"\"\n",
        "\n",
        "            if not api_key.strip():\n",
        "                return None, \"Please enter your Gemini API key\", \"\"\n",
        "\n",
        "            # Configure Gemini\n",
        "            config_result = tts_system.configure_gemini(api_key)\n",
        "            if \"ERROR\" in config_result:\n",
        "                return None, config_result, \"\"\n",
        "\n",
        "            # Detect language\n",
        "            lang_code, lang_name = tts_system.detect_language(text)\n",
        "\n",
        "            processed_text = text\n",
        "            enhancement_info = \"\"\n",
        "\n",
        "            if enhance:\n",
        "                processed_text, enhancement_status = tts_system.enhance_text_with_gemini(text, category)\n",
        "                enhancement_info = f\"Gemini Enhancement: {enhancement_status}\"\n",
        "\n",
        "            try:\n",
        "                audio_path = tts_system.text_to_speech(processed_text, lang_code, slow)\n",
        "                status_message = f\"SUCCESS: Speech generated!\\nDetected Language: {lang_name}\\n{enhancement_info}\"\n",
        "                return audio_path, status_message, processed_text\n",
        "            except Exception as e:\n",
        "                return None, f\"ERROR: {str(e)}\", \"\"\n",
        "\n",
        "        tts_generate_btn.click(\n",
        "            fn=process_tts_only,\n",
        "            inputs=[tts_text_input, api_key_input, user_category, tts_enhance_checkbox, tts_slow_speech_checkbox],\n",
        "            outputs=[tts_audio_output, tts_status_output, tts_enhanced_text_output]\n",
        "        )\n",
        "\n",
        "        # Granite Model Initialization\n",
        "        granite_init_btn.click(\n",
        "            fn=tts_system.initialize_granite_model,\n",
        "            outputs=granite_status\n",
        "        )\n",
        "\n",
        "        # Speech-to-Text\n",
        "        stt_transcribe_btn.click(\n",
        "            fn=tts_system.speech_to_text_granite,\n",
        "            inputs=stt_audio_input,\n",
        "            outputs=[stt_transcribed_output, stt_status]\n",
        "        )\n",
        "\n",
        "        # Sample text buttons\n",
        "        sample_hindi.click(\n",
        "            lambda: \"नमस्ते! यह एक उन्नत बहुभाषी टेक्स्ट टू स्पीच सिस्टम है।\",\n",
        "            outputs=input_text\n",
        "        )\n",
        "\n",
        "        sample_telugu.click(\n",
        "            lambda: \"నమస్కారం! ఇది ఒక అధునాతన బహుభాషా టెక్స్ట్ టు స్పీచ్ సిస్టమ్.\",\n",
        "            outputs=input_text\n",
        "        )\n",
        "\n",
        "        sample_urdu.click(\n",
        "            lambda: \"السلام علیکم! یہ ایک جدید کثیر لسانی ٹیکسٹ ٹو اسپیچ سسٹم ہے۔\",\n",
        "            outputs=input_text\n",
        "        )\n",
        "\n",
        "        sample_english.click(\n",
        "            lambda: \"Hello! This is an advanced multilingual text-to-speech system powered by Gemini AI and IBM Granite.\",\n",
        "            outputs=input_text\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Installation function\n",
        "def install_requirements():\n",
        "    \"\"\"Install required packages for Google Colab\"\"\"\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    packages = [\n",
        "        'gradio',\n",
        "        'google-generativeai',\n",
        "        'gtts',\n",
        "        'langdetect',\n",
        "        'transformers>=4.52.4',\n",
        "        'torchaudio',\n",
        "        'peft',\n",
        "        'soundfile',\n",
        "        'huggingface-hub',\n",
        "        'PyPDF2'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
        "            print(f\"SUCCESS: {package} installed successfully\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"ERROR: Failed to install {package}\")\n",
        "\n",
        "def run_app():\n",
        "    \"\"\"Launch the Echo Verse audiobook creation tool\"\"\"\n",
        "    print(\"Starting Echo Verse - AI-Powered Audiobook Creation Tool...\")\n",
        "    print(\"The app will be accessible via the generated Gradio link\")\n",
        "    print(f\"Device: {tts_system.device}\")\n",
        "\n",
        "    interface = create_interface()\n",
        "\n",
        "    # Launch with public sharing for Colab compatibility\n",
        "    interface.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        inbrowser=True,\n",
        "        show_error=True\n",
        "    )\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Installing required packages...\")\n",
        "    install_requirements()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ECHO VERSE - AI-POWERED AUDIOBOOK CREATION TOOL\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Features:\")\n",
        "    print(\"   * Automatic language detection (25+ languages)\")\n",
        "    print(\"   * Gemini AI text enhancement\")\n",
        "    print(\"   * IBM Granite speech-to-text\")\n",
        "    print(\"   * High-quality audiobook generation\")\n",
        "    print(\"   * User category customization\")\n",
        "    print(\"   * Black UI with green accents\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Required: Gemini API key from https://makersuite.google.com/app/apikey\")\n",
        "    print(\"GPU recommended for Granite model performance\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    run_app()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}